{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia_bloknota_Lub4_TextAnalysis_ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtyGsN41cJfW"
      },
      "source": [
        "# Введение\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUax1Iu4-uMR"
      },
      "source": [
        "Сегодня мы продолжим изучение применения методов анализа данных и машинного обучения на практических примерах. В прошлой ЛР мы с вами разбирались с задачей кластеризации. Теперь вас ждет новая работа - «Задачи о паспортах» (Задание №2).\n",
        "При решении будут показаны основы анализа текстовой информации, а также ее кодирование для построения модели с помощью Python и модулей для анализа данных (pandas, scikit-learn, pymorphy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvhsHcjBBodz"
      },
      "source": [
        "Документация\n",
        "* [pandas](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "* [scikit-learn](https://scikit-learn.org/stable/)\n",
        "* [pymorphy](https://pymorphy2.readthedocs.io/en/latest/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnA_utIej95A"
      },
      "source": [
        "Постановка задачи: \n",
        "\n",
        "При работе с большим объёмом данных важно поддерживать их чистоту. А при заполнении заявки на банковский продукт необходимо указывать полные паспортные данные, в том числе и поле «кем выдан паспорт», число различных вариантов написаний одного и того же отделения потенциальными клиентами может достигать нескольких сотен. Важно понимать, не ошибся ли клиент, заполняя другие поля: «код подразделения», «серию/номер паспорта». Для этого необходимо сверять «код подразделения» и «кем выдан паспорт».\n",
        "Задача заключается в том, чтобы проставить коды подразделений для записей из тестовой выборки, основываясь на обучающей выборке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVscrtB571BU"
      },
      "source": [
        " Загрузим данные и все библиотеки, которые нам пригодятся. \n",
        " \n",
        " Для полного понимания и дополнительной информации вы можете обращаться к документации\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDarpaS_8HJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344ac384-5a2a-435c-ba55-e5a0158c422b"
      },
      "source": [
        "pip install pymorphy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqQj2wqyqxna"
      },
      "source": [
        "from pandas import read_csv\n",
        "import pymorphy2\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY5bEcRi70dB"
      },
      "source": [
        "Давайте посмотрим, как выглядят наши данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWqDtCRr80SJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "3de0a47d-b576-4581-c81f-d9b15a92595f"
      },
      "source": [
        "train = read_csv('https://static.tcsbank.ru/documents/olymp/passport_training_set.csv',';', index_col='id' ,encoding='cp1251')\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-09e05d88ec3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://static.tcsbank.ru/documents/olymp/passport_training_set.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cp1251'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     )\n\u001b[1;32m    439\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# TODO: fsspec can also handle HTTP via requests, but leaving this unchanged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34KOgIhp81Kb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "e4a1da76-d9b3-4596-dec5-d35c0fc98030"
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passport_div_code</th>\n",
              "      <th>passport_issuer_name</th>\n",
              "      <th>passport_issue_month/year</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>422008</td>\n",
              "      <td>БЕЛОВСКИМ УВД КЕМЕРОВСКОЙ ОБЛАСТИ</td>\n",
              "      <td>11M2001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500112</td>\n",
              "      <td>ТП №2 В ГОР. ОРЕХОВО-ЗУЕВО ОУФМС РОССИИ ПО МО ...</td>\n",
              "      <td>03M2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>642001</td>\n",
              "      <td>ВОЛЖСКИМ РОВД ГОР.САРАТОВА</td>\n",
              "      <td>04M2002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>162004</td>\n",
              "      <td>УВД МОСКОВСКОГО РАЙОНА Г.КАЗАНЬ</td>\n",
              "      <td>12M2002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>80001</td>\n",
              "      <td>ОТДЕЛОМ ОФМС РОССИИ ПО РЕСП КАЛМЫКИЯ В Г ЭЛИСТА</td>\n",
              "      <td>08M2009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    passport_div_code  ... passport_issue_month/year\n",
              "id                     ...                          \n",
              "1              422008  ...                   11M2001\n",
              "2              500112  ...                   03M2009\n",
              "3              642001  ...                   04M2002\n",
              "4              162004  ...                   12M2002\n",
              "5               80001  ...                   08M2009\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40fXISlhpjmz"
      },
      "source": [
        "Мы с вами видим таблицу, состоящую из 3 колонок - Кода подразделения, Кем выдан паспорт и дата выдачи, в формате mm/yyyy. На данных из колонок passport_issuer_name и passport_issue_month/year мы будем тренировать наши данные. Данные из колонки passport_div_code - наш таргет. Именно код подразделения мы будем предсказывать.\n",
        "\n",
        "Т.е. на passport_issuer_name(Кем выдан) и passport_issue_month/year(Дата выдачи) мы должны тренировать наши данные, а предсказывать будем passport_div_code (Код подразделения)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAw17JboMjzi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnYVlWEbp4x_"
      },
      "source": [
        "Как вы можете заметить, данные в колонке passport_issuer_name представлены не в числовом, уже знакомым для нас, формате, а в текстовом. А это значит что нам предстоит привести текст в нормальную форму. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkvOqoRQ4h4h"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Предварительная обработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqEu10D64p-5"
      },
      "source": [
        "Теперь можно посмотреть как пользователи записывают поле «кем выдан паспорт» на примере какого-либо подразделения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A0c_41j7UbZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a4422517-b9c6-409d-a93f-08f3a40a2ea6"
      },
      "source": [
        "example_code = train.passport_div_code[train.passport_div_code.duplicated()].values[0]\n",
        "for i in train.passport_issuer_name[train.passport_div_code == example_code].drop_duplicates():\n",
        "    print (i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ОТДЕЛЕНИЕМ УФМС РОССИИ ПО РЕСПУБЛИКЕ КАРЕЛИЯ В МЕДВЕЖ. Р-Е\n",
            "ОТДЕЛЕНИЕМ УФМС РОССИИ ПО Р. КАРЕЛИЯ В МЕДВЕЖЬЕГОРСКОМ РАЙОНЕ\n",
            "ОТДЕЛЕНИЕМ УФМС РОССИИ ПО РЕСП КАРЕЛИЯ В МЕДВЕЖЬЕГОРСКОМ Р-НЕ\n",
            "ОТДЕЛЕНИЕМ УФМС РОССИИ ПО РЕСПУБЛИКЕ КАРЕЛИЯ В МЕДВЕЖЬЕГОРСКОМ РАЙОНЕ\n",
            "ОУФМС РОССИИ ПО РЕСПУБЛИКЕ КАРЕЛИЯ В МЕДВЕЖЬЕГОРСКОМ РАЙОНЕ\n",
            "УФМС РОССИИ ПО РК В МЕДВЕЖЬЕГОРСКОМ РАЙОНЕ\n",
            "ОТДЕЛЕНИЕМ УФМС РОССИИ ПО РЕСПУБЛИКЕ КАРЕЛИЯ МЕДВЕЖЬЕГОРСКОМ Р-ОНЕ\n",
            "ОТДЕЛЕНИЕМ УФМС РОССИИ ПО РК В МЕДВЕЖЬЕГОРСКОМ РАЙОНЕ\n",
            "ОТДЕЛЕНИЕМ УФМС РОССИИ ПО РЕСПУБЛИКЕ КОРЕЛИЯ В МЕДВЕЖИГОРСКОМ РАЙОНЕ\n",
            "УФМС РОССИИ ПО Р. КАРЕЛИЯ МЕДВЕЖЬЕГОРСКОГО Р-НА\n",
            "ОТДЕЛОМ УФМС РОССИИ ПО РЕСПУБЛИКЕ КАРЕЛИЯ В МЕДВЕЖЬЕГОРСКОМ\n",
            "УФМС РЕСПУБЛИКИ КАРЕЛИИ МЕДВЕЖЬЕГОРСКОГО Р-ОН\n",
            "МЕДВЕЖЬЕГОРСКИМ ОВД\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47AKgQLj4qDH"
      },
      "source": [
        "Как можно заметить нужное нам поле действительно заполняется криво. Но для нормально кодирования мы должны привести это поле к более-менее нормальному (однозначному) виду.\n",
        "Для начала вам предлагается привести все записи к одному регистру, например, чтобы все буквы стали строчными. Это легко сделать с помощью атрибута str, столбца DataFrame'a. Этот атрибут позволяет работать со столбцом как с строкой, а также выполнять различного рода поиск и замену по регулярным выражениям:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrLS_d3d_tBI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4bb1f221-f4c2-4860-d760-394638ff9a61"
      },
      "source": [
        "train.passport_issuer_name = train.passport_issuer_name.str.lower()\n",
        "train[train.passport_div_code == example_code].head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passport_div_code</th>\n",
              "      <th>passport_issuer_name</th>\n",
              "      <th>passport_issue_month/year</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>100010</td>\n",
              "      <td>отделением уфмс россии по республике карелия в...</td>\n",
              "      <td>04M2008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>100010</td>\n",
              "      <td>отделением уфмс россии по р. карелия в медвежь...</td>\n",
              "      <td>10M2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5642</th>\n",
              "      <td>100010</td>\n",
              "      <td>отделением уфмс россии по респ карелия в медве...</td>\n",
              "      <td>08M2008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6668</th>\n",
              "      <td>100010</td>\n",
              "      <td>отделением уфмс россии по республике карелия в...</td>\n",
              "      <td>08M2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>100010</td>\n",
              "      <td>отделением уфмс россии по республике карелия в...</td>\n",
              "      <td>08M2012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      passport_div_code  ... passport_issue_month/year\n",
              "id                       ...                          \n",
              "19               100010  ...                   04M2008\n",
              "22               100010  ...                   10M2009\n",
              "5642             100010  ...                   08M2008\n",
              "6668             100010  ...                   08M2011\n",
              "8732             100010  ...                   08M2012\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb7Mmdf34qH4"
      },
      "source": [
        "C регистром определились. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7rDTL2s-jLa"
      },
      "source": [
        "####[Регулярные](https://tproger.ru/translations/regular-expression-python/) выражения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTTPCZOX1dYo"
      },
      "source": [
        "Говоря простым языком, регулярное выражение — это последовательность символов, используемая для поиска и замены текста в строке или файле.\n",
        "\n",
        "Регулярные выражения используют два типа символов:\n",
        "\n",
        "* специальные символы: как следует из названия, у этих символов есть специальные значения. Аналогично символу *, который как правило означает «любой символ» (но в регулярных выражениях работает немного иначе, о чем поговорим ниже);\n",
        "* литералы (например: a, b, 1, 2 и т. д.).\n",
        "\n",
        "В Python для работы с регулярными выражениями есть модуль re. Для использования его нужно импортировать:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TbNKQGr0J6r"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrFyR0Mo4XLq"
      },
      "source": [
        "Операторы и их описание\n",
        "\n",
        ".\tОдин любой символ, кроме новой строки \\n.\n",
        "\n",
        "\\w\tЛюбая цифра или буква (\\W — все, кроме буквы или цифры)\n",
        "\n",
        "\\d\tЛюбая цифра [0-9] (\\D — все, кроме цифры)\n",
        "\n",
        "\\s\tЛюбой пробельный символ (\\S — любой непробельный символ)\n",
        "\n",
        "[..]\tОдин из символов в скобках ([^..] — любой символ, кроме тех, что в \n",
        "скобках)\n",
        "\n",
        "\\\tЭкранирование специальных символов (\\. означает точку или \\+ — знак «плюс»)\n",
        "\n",
        "a|b\tСоответствует a или b\n",
        "\n",
        "()\tГруппирует выражение и возвращает найденный текст\n",
        "\n",
        "\\t, \\n, \\r\tСимвол табуляции, новой строки и возврата каретки соответственно"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuM_GSOP5V1a"
      },
      "source": [
        "Попробуйте с помощью функции re.findall() найти:\n",
        "\n",
        "* судьба, судоходство, судьбы, сударыня в тексте: \"Анатолий любил заниматься судоходством и верил, что это его судьба! Но ирония судьбы в том, что сударыня Екатерина так не думала\" ([а-я] - любая буква. [а-я]* - любые буквы дальше)\n",
        "* дворе, двора в тексте: \"На дворе трава, на траве дрова Не руби дрова на траве двора.\"\n",
        "* покупки, покупочки в тексте: \"Расскажите про покупки, Про какие про покупки? Про покупки, про покупки, Про покупочки мои.\"\n",
        "* чертили, чертенка, чертеж,: \"Четыре черненьких, чумазеньких чертенка Чертили черными чернилами чертеж.\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7tWNKHaBPPo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36b6588d-818a-484c-c7ab-2d22f0a36725"
      },
      "source": [
        "re.findall('(по\\куп[а-я]*|с\\куп[а-я]*)', 'Мы любим наших покупателей. Рады когда они покупают что-то. А еще у нас лучшие скупщики') #покупателей, покупают, скупщики"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['покупателей', 'покупают', 'скупщики']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKXgyEJ_5NTl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7be48b0a-fc63-4e72-a627-bf07804cb2e5"
      },
      "source": [
        "re.findall('суд[а-я]*', 'Анатолий любил заниматься судоходством и верил, что это его судьба! Но ирония судьбы в том, что сударыня Екатерина так не думала') ## - ВАШ КОД ТУТ - ##"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['судоходством', 'судьба', 'судьбы', 'сударыня']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnYvOtYE9B1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c113b32-6e24-466e-ccdc-b29e80e498c9"
      },
      "source": [
        "re.findall('двор[а-я]', 'На дворе трава, на траве дрова Не руби дрова на траве двора.') ## - ВАШ КОД ТУТ - ##"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['дворе', 'двора']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mtfTv5x9B9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a1952fb-c052-414c-a382-cfe724bc8915"
      },
      "source": [
        "re.findall('покуп[а-я]*', 'Расскажите про покупки, Про какие про покупки? Про покупки, про покупки, Про покупочки мои.') ## - ВАШ КОД ТУТ - ##"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['покупки', 'покупки', 'покупки', 'покупки', 'покупочки']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9FZZuYV9CBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f74d968-87df-4c1e-9b8d-58deef1f5a0f"
      },
      "source": [
        "re.findall('[Чч]ерт[а-я]*', 'Четыре черненьких, чумазеньких чертенка Чертили черными чернилами чертеж.') ## - ВАШ КОД ТУТ - ##"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['чертенка', 'Чертили', 'чертеж']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBjLvVt7BSbx"
      },
      "source": [
        "##### Сокращения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl_qPivA-PJP"
      },
      "source": [
        "Далее надо по возможности избавиться от популярных сокращений, например район, город и т.д. Сделаем это с помощью регулярных выражений. Pandas предоставляет удобное использование регулярных выражений применительно к каждому столбцу. Это выглядит так: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVg800RH9Fx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b384a3e-b1c9-4a98-bce2-b86e03629d00"
      },
      "source": [
        "result = re.search(r'р-(а|й|о|н|е)*', u'отделением уфмс россии по р. карелия в медвежь р-не') # Поиск в строке любых сокращений типа р- (а ИЛИ й ИЛИ о ИЛИ н ИЛИ е)\n",
        "result # в результате нам выдаст начало и конец того, что искали"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(47, 51), match='р-не'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqFAOnsMCp99"
      },
      "source": [
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u'р-(а|й|о|н|е)*',u'район')\n",
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u' г( |\\.|(ор(\\.| )))', u' город ')\n",
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u' р(\\. |есп\\. |к(\\. | ))', u' республика ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB5ma3HcBZlA"
      },
      "source": [
        "Пропишите так же для сокращений административный(адм. админ. администр. итд), округ(окр., округа, окр), и административный округ(ао)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7U30wq4B6xU"
      },
      "source": [
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u' окр( |\\.|(уга))', u' округ ')\n",
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u' адм[а-я]*( |\\.)', u' административный ')\n",
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u'ао', u'административный округ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z391g-gWBfGM"
      },
      "source": [
        "##### Символы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW5TwwCNEhL8"
      },
      "source": [
        "Теперь избавимся от всех лишних символов, кроме русских букв, дефисов и пробелов. Это связано с тем, что паспорт о одинаковым подразделением может выдаваться отделами с разными номерами, и это ухудшит дальнейшую кодировку:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZP6kf3QAy6O"
      },
      "source": [
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u' - ?', u'-')\n",
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u'[^а-я -]','')\n",
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u'- ',' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHmEmyaVCOQc"
      },
      "source": [
        "Избавтесь от пробелов так же"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4a3FKlHCNo-"
      },
      "source": [
        "train.passport_issuer_name = train.passport_issuer_name.str.replace(u'\\s', u' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53yAUdR8BjKs"
      },
      "source": [
        "##### Аббревиатуры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Klqt07Aznw"
      },
      "source": [
        "На следующем шаге, надо расшифровать аббревиатуры, типа УВД, УФНС, ЦАО, ВАО и т.д., т.к. этих их в принципе не много, но на качестве дальнейшего кодирования это скажется положительно. Например если у нас будет две записи «УВД» и «управление внутренних дел», то закодированы они будут по разному, т. к. для компьютера это разные значения.\n",
        "Итак перейдем к расшифровке. И, для начала, заведем словарь сокращений, с помощью которого мы и сделаем расшифровку:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2tnK1-qCyMc"
      },
      "source": [
        "Добавьте в этот словарик еще аббревиатуры юао(южный), юзао(юго-западный), ювао(юго-восточный), пс(паспортный стол), тп(территориальный пункт)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MCxog9QAzty"
      },
      "source": [
        "sokr = {u'нао': u'ненецкий автономный округ',\n",
        "u'хмао': u'ханты-мансийский автономный округ',\n",
        "u'чао': u'чукотский автономный округ',\n",
        "u'янао': u'ямало-ненецкий автономный округ',\n",
        "u'вао': u'восточный административный округ',\n",
        "u'цао': u'центральный административный округ',\n",
        "u'зао': u'западный административный округ',\n",
        "u'cао': u'северный административный округ',\n",
        "u'свао': u'северо-восточный округ',\n",
        "u'сзао': u'северо-западный округ',\n",
        "u'оуфмс': u'отдел управление федеральной миграционной службы',\n",
        "u'офмс': u'отдел федеральной миграционной службы',\n",
        "u'уфмс': u'управление федеральной миграционной службы',\n",
        "u'увд': u'управление внутренних дел',\n",
        "u'ровд': u'районный отдел внутренних дел',\n",
        "u'говд': u'городской отдел внутренних дел',\n",
        "u'рувд': u'районное управление внутренних дел',\n",
        "u'овд': u'отдел внутренних дел',\n",
        "u'оувд': u'отдел управления внутренних дел',\n",
        "u'мро': u'межрайонный отдел',\n",
        "u'юао' : u'южный административный округ', \n",
        "u'юзао' : u'юго-западный административный округ', \n",
        "u'ювао' : u'юго-восточный административный округ', \n",
        "u'пс' : u'паспортный стол', \n",
        "u'тп' : u'территориальный пункт'}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClQoMFoJEDNH"
      },
      "source": [
        "Теперь, собственно произведем расшифровку абривеатур и отформатируем полученные записи:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sfBDi23IDnq"
      },
      "source": [
        "for i in sokr.keys():\n",
        "    train.passport_issuer_name = train.passport_issuer_name.str.replace(u'( %s )|(^%s)|(%s$)' % (i,i,i), u' %s ' % (sokr[i]))\n",
        "    \n",
        "#удалим лишние пробелы в конце и начале строки\n",
        "train.passport_issuer_name = train.passport_issuer_name.str.lstrip()\n",
        "train.passport_issuer_name = train.passport_issuer_name.str.rstrip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3RRZDNOJ-k2"
      },
      "source": [
        "Нам нужно найти такое k, начиная с которого значение критерия k-means будет убывать не слишком быстро. Этот эффект очень визуально похож на локоть и отсюда, собственно, название этого метода (Метод Локтя). Например, для данных на рисунке выше, таким k будет k равное 4. Важно понимать, что все эти эвристики и меры качества в кластеризации носят лишь рекомендательный характер."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NND1I316jnmL"
      },
      "source": [
        "####Столбец - Дата выдачи:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPgyc2MPjhs8"
      },
      "source": [
        "Предварительный этап обработки поля «кем выдан паспорт» на этом закончим. И перейдем к полю, в котором находится дата выдачи.\n",
        "Как можно заметить данные в нем хранятся в виде: месяцMгод.\n",
        "Соответственно можно просто убрать букву «M» и привести поле к числовому типу. Но если хорошо подумать, то это поле можно удалить, т.к. на один месяц в году может приходиться несколько подразделений выдававших паспорт, и соответственно это может испортить нашу модель. Исходя из этого удалим его из выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiQrmYAylg1p"
      },
      "source": [
        "train = train.drop(['passport_issue_month/year'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDPczr9jmI-y"
      },
      "source": [
        "Теперь мы можем перейти к анализу данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJKPDhW6mhkP"
      },
      "source": [
        "##Анализ данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4TK23v3mocr"
      },
      "source": [
        "Итак, данные для построения модели у нас есть, но они находятся в текстовом виде. Для построения модели хорошо бы было их закодировать в числовом виде.\n",
        "Авторы пакета scikit-learn заботливо о нас позаботились и добавили несколько способов для извлечения и кодирования текстовых данных.\n",
        "\n",
        "* [FeatureHasher](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html#sklearn.feature_extraction.FeatureHasher)\n",
        "\n",
        "* [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)\n",
        "\n",
        "* [HashingVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ66O07qmom0"
      },
      "source": [
        "**FeatureHasher** преобразовывает строку в числовой массив заданной длинной с помощью хэш-функции (32-разрядная версия Murmurhash3)\n",
        "\n",
        "**CountVectorizer** преобразовывает входной текст в матрицу, значениями которой, являются количества вхождения данного ключа(слова) в текст. В отличие от FeatureHasher имеет больше настраиваемых параметров(например можно задать токенизатор), но работает медленнее.\n",
        "Для более точного понимания работы CountVectorizer приведем простой пример. Допустим есть таблица с текстовыми значениями:\n",
        "\n",
        "раз два три\n",
        "\n",
        "три четыре два два\n",
        "\n",
        "раз раз раз четыре\n",
        "\n",
        "\n",
        "Для начала CountVectorizer собирает уникальные ключи из всех записей, в нашем примере это будет:\n",
        "\n",
        "[раз, два, три, четыре]\n",
        "\n",
        "Длина списка из уникальных ключей и будет длиной нашего закодированного текста (в нашем случае это 4). А номера элементов будут соответствовать, количеству раз встречи данного ключа с данным номером в строке:\n",
        "\n",
        "раз два три --> [1,1,1,0]\n",
        "три четыре два два --> [0,2,1,1]\n",
        "\n",
        "Соответственно после кодировки, применения данного метода мы получим:\n",
        "\n",
        "1,1,1,0\n",
        "\n",
        "0,2,1,1\n",
        "\n",
        "3,0,0,1\n",
        "\n",
        "\n",
        "**HashingVectorizer** является смесью двух выше описанных методов. В нем можно и регулировать размер закодированной строки (как в FeatureHasher) и настраивать токенизатор (как в CountVectorizer). К тому же его производительность ближе к FeatureHasher.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFIaa7C4movp"
      },
      "source": [
        "\n",
        "Итак, вернемся к анализу. Если мы посмотрим по внимательнее на наш набор данных то можно заметить, что есть похожие строки но записанные по разному например: \"… республика карелия...\" и \"… по республике карелия...\".\n",
        "\n",
        "Для этой задачи хорошо подходит pymorphy или nltk. Мы будем использовать первый, т.к. он изначально создавался для работы с русским языком. Итак, функция которая будет отвечать за нормализацию и очиску строки выглядит так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pmOi4RhQfW_"
      },
      "source": [
        "def f_tokenizer(s):\n",
        "    path=\"/usr/local/lib/python3.6/dist-packages/pymorphy2_dicts_ru/data\"\n",
        "    morph = pymorphy2.MorphAnalyzer(path=path, lang='ru')\n",
        "    if isinstance(s, str):\n",
        "        t = s.split(' ')\n",
        "    else:\n",
        "        t = s\n",
        "    f = []\n",
        "    for j in t:\n",
        "        m = morph.parse(j.replace('.',''))\n",
        "        if len(m) != 0:\n",
        "            wrd = m[0]\n",
        "            if wrd.tag.POS not in ('NUMR','PREP','CONJ','PRCL','INTJ'):\n",
        "                f.append(wrd.normal_form)\n",
        "    return f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZb8n71x5-6Y"
      },
      "source": [
        "Функция делает следующее:\n",
        "* Сначала она преобразовывает строку в список\n",
        "* Затем для всех слов производит разбор\n",
        "* Если слово является числительным, предикативном, предлогом, союзом, частицей или междометием не включаем его в конечный набор\n",
        "* Если слово не попало в предыдущий список, берем его нормальную форму и добавляем в финальный набор\n",
        "\n",
        "Теперь, когда есть функция для нормализации можно приступить к кодированию с помощью метода CountVectorizer. Он выбран потому, что ему можно передать нашу функцию, как токенизатор и он составит список ключей по значениям полученным в результате работы нашей функции:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOAjjat39rN8"
      },
      "source": [
        "coder = HashingVectorizer(tokenizer=f_tokenizer, n_features=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxAXonYjTYNe"
      },
      "source": [
        "Как можно заметить при создании метода кроме токенизатора мы задаем еще один параметр n_features. Через данный параметр задается длина закодированной строки (в нашем случае строка кодируется при помощи 256 столбцов). Кроме того, у HashingVectorizer есть еще одно преимущество перед CountVectorizer, но сразу может выполнять нормализацию значений, что хорошо для таких алгоритмов, как SVM.\n",
        "Теперь применим наш кодировщик к обучающему набору:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whMaNNF8VHbl"
      },
      "source": [
        "TrainNotDuble = train.iloc[1:10000].drop_duplicates() \n",
        "# тут мы берем значение от 1 до 10000. Выполняться код в таком случае будет 8:30 минут. \n",
        "# Можете взять больше или меньше - ждать придется соответственно, но и работа функции изменится!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7XzmhxiTh2H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "03df9881-6663-4764-9cbc-542766e8c412"
      },
      "source": [
        "trn = coder.fit_transform(TrainNotDuble.passport_issuer_name.tolist()).toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z4JvCfgLH4B"
      },
      "source": [
        "#Построение модели\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgb-vSD-L5qx"
      },
      "source": [
        "Для начала нам надо задать значения для столбца, в котором будут содержаться метки классов:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6XbK-EQL2gZ"
      },
      "source": [
        "target = TrainNotDuble.passport_div_code.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdpeQ7OHMlWz"
      },
      "source": [
        "Задача, которую мы решаем сегодня, принадлежит к классу задач классификации со множеством классов. Для решения данной задачи лучше всего подошел алгоритм RandomForest. Остальные алгоритмы показали очень плохие результаты (менее 50%) поэтому я решил не занимать место в статье. При желании любой интересующийся может проверить данные результаты.\n",
        "Для оценки качества классификации будем использовать количество документов по которым принято правильное решение, т. е.\n",
        "\n",
        "Accuracy = {P} / {N}\n",
        "\n",
        ", где P — количество документов по которым классификатор принял правильное решение, а N – размер обучающей выборки.\n",
        "В пакете scikit-learn для этого есть функция: accuracy_score\n",
        "Перед началом построения собственно модели, давайте сократим размерность с помощью «метода главных компонент», т.к. 256 столбцов для обучения довольно много:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCeZJjVvMiqE"
      },
      "source": [
        "pca = PCA(n_components = 15)\n",
        "trn = pca.fit_transform(trn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfkD2XL2NnG1"
      },
      "source": [
        "Модель будет выглядеть так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcur3NAKNelZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30f35b15-4cf6-446b-9e23-c7184eeda7dd"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators = 100, criterion='entropy')\n",
        "\n",
        "TRNtrain, TRNtest, TARtrain, TARtest = train_test_split(trn, target, test_size=0.15)\n",
        "model.fit(TRNtrain, TARtrain)\n",
        "print ('accuracy_score: ', accuracy_score(TARtest, model.predict(TRNtest)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score:  0.5154639175257731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zv_L_U8eGod"
      },
      "source": [
        "#Заключение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wei52dp29ma"
      },
      "source": [
        "В качестве вывода нужно отметить, что полученная точность в '*ваше значение*' близка к угадыванию. Чтобы улучшить нужно при первичной обработке обработать грамматические ошибки и различного рода описки. Данное действие также скажется положительно и на словаре при кодировании поля, т. е. его размер уменьшиться и соответственно уменьшиться длина строки после ее кодировки.\n",
        "Кроме того этап обучения тестовой выборки опущен специально, т. к. в нем нет ничего особенного, кроме его приведения к нужному виду (это можно легко сделать взяв за основу преобразования обучающей выборки)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khEZNNIKkjOb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}